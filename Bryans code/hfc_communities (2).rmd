---
title: "Hydrofluorocarbon Production Community Characteristics"
author: "NCEE"
date: "2/28/2021"
output: word_document
---

```{r setup, include=FALSE, echo=FALSE}

knitr::opts_chunk$set(echo = TRUE)

# options ----------------------------------------------------------------------

# end year of the 5-year ACS sample to draw data from
year = 2019

# buffer distance for the proximity analysis [miles]
buffer_dist = 3


# load libraries ---------------------------------------------------------------

library(tidycensus)
library(tidyverse)
library(sf)           
library(foreach)
library(doSNOW)
library(scales)
library(odbc)
library(colorspace)
library(readxl)
library(knitr)

# source("download_file.R")


# supporting function to download files ----------------------------------------

# download_file.R
#
# downloads a file if not present locally and extracts the contents if it is a
# compressed archive
#
# inputs:
#   url: url where the remote file resides
#   file_name: name of the remote file
#   dir: local directory to save the file [defulat is "."]
#   check_file: optional name of local file, where if present the download will
#               not occur. useful if the remote file is a compressed archive and
#               it shouldn't be downloaded if its contents is already present
#   tolower: covnert file names in a zip file to lower case [default is FALSE]
#

download_file = function(url,file_name,dir=".",check_file=NA,tolower=F) {
  
  library(httr)
  
  # create the directory if needed
  if (!dir.exists(dir))
    dir.create(dir)
  
  # if no check file name is provided use the remote file name
  if (is.na(check_file))
    check_file = file_name
  
  # if the check file is present then do nothing further
  if (file.exists(file.path(dir,check_file)))
    return()
  
  # download the file
  cat(paste0("downloading ",file_name,"... \n"))
  GET(paste0(url,file_name),
      write_disk(file.path(dir,file_name),overwrite=TRUE),
      progress())
  
  # if the file is a zip archive extract the contents and delete the archive
  if (tools::file_ext(file_name)=="zip") {
    cat("extracting zip file...\n")
    unzip(file.path(dir,file_name),exdir=dir)
    if (tolower) {
      files = unzip(file.path(dir,file_name),list=T)
      for (file in files)
        file.rename(file.path(dir,file),file.path(dir,tolower(file)))
    }
    file.remove(file.path(dir,file_name))
  }
  
  cat("\n")
  
}



# download the acs data --------------------------------------------------------

# geography at which to draw data
geography = "block group"

# variables to download from the ACS
# B01001_001	Estimate!!Total:
# B03002_003	Estimate!!Total:!!Not Hispanic or Latino:!!White alone  
# B06011_001	Estimate!!Median income in the past 12 months --!!Total:
# C17002_002  Ratio of income to the poverty level 
# B17011_001  Aggregate income deficit in the past 12 months
# B19013_001  Median Household Income In The Past 12 Months 
variables = c(pop="B01001_001",white="B03002_003",pov50="C17002_002",
              pov99="C17002_003",deficit="B17011_001",income="B19013_001")

# cache the geometries downloaded from census
options(tigris_use_cache=TRUE)

# census api key
# get one at: https://api.census.gov/data/key_signup.html
# census_api_key("NEED TO USE YOUR CENSUS API HERE")

# file name for the stored acs data
acs_file = paste0("acs_data_",year,"_",geography,".RData")

# download the acs data if it doesn't exist
if (file.exists(file.path("acs_data",acs_file))) {
  
  load(file.path("acs_data",acs_file))
  
} else {

  # setup the cluster to download and process the data
  cl = makeCluster(3,outfile="")
  registerDoSNOW(cl)
  
  # list of state abbreviations plus DC
  states = c(state.abb,"DC")
  
  # tidycensus will only return tract or block group data for a single state, so
  # we need to loop through each state and combine the results
  data = foreach (i=1:length(states),.combine=rbind,
                  .packages=c("tidycensus","tidyverse")) %dopar% {
                    print(paste("starting state:",states[i]))
                    get_acs(geography=geography,
                            state=states[i],
                            variables=variables, 
                            year=year,
                            geometry=TRUE) %>%
                      select(-NAME,-moe) 
                  }
  
  # save the acs data
  if (!dir.exists("acs_data"))
    dir.create("acs_data")
  save(file=file.path("acs_data",acs_file),list="data")
  
  stopCluster(cl)

}



# get the nata cancer risk data ------------------------------------------------

# directory to store the nata data
nata_dir = "nata_data"

# 2014 nata file containing national cancer risks by toxic
nata_file = "nata2014v2_national_cancerrisk_by_tract_poll.xlsx"

# download the nata data if it doesn't already exist
download_file("https://www.epa.gov/sites/production/files/2018-08/",
              nata_file,
              dir=nata_dir)

# load the nata data
nata_data = read_excel(file.path(nata_dir,nata_file)) %>%
            rename(total_risk='Total Cancer Risk (per million)') 



# get the production facility data ---------------------------------------------

# use the ghg reporting program data for flurocarbon producers to locate the 
# facilities

# get_ef_data: downloads the specified table from epa's envirofacts data base
# with the option to only download data for a specific year
get_ef_data = function(table,year=NA,year_var="YEAR") {
  
  # url for the epa enviro facts api
  url = "https://data.epa.gov/efservice/"
  
  # create the api request
  req = paste0(url,table)
  
  # if a specific year is requested define that
  if (!is.na(year))
    req = paste0(req,"/",year_var,"/",year)
  
  # define the output type to be returned
  req = paste0(req,"/","CSV")
  
  # get the data
  data = read.csv(req,stringsAsFactors=FALSE)
  
  # remove the table name from the column names
  names(data) = tolower(gsub(".*[.](.*)","\\1",names(data)))
  
  return(data)
  
}

# get facilities reporting as fluronated gas producers in the ghg reporting 
# program under subpart L and merge in detailed facility data from the ghg
# reporting program including lat/lon coordinates
facilities = get_ef_data("EF_L_FACILITYDETAILS",year=year,
                         year_var="reporting_year") %>%
             left_join(get_ef_data("PUB_DIM_FACILITY",year=year),
                       by="facility_id")

# convert the data frame of facility points to an sf object to work with spatial
# data functions - use same coordinate system as the acs geometry
facilities = st_as_sf(facilities, 
                      coords=c(x="longitude",y="latitude"), 
                      crs=4326) %>%
             st_transform(3488) 



# conduct proximity analysis ---------------------------------------------------

# add the census tract to the data in case the geography is a lower resolution
data = data %>%
       mutate(Tract=substr(GEOID,1,11))

# get the geography geometry from the acs data
shp = data %>%
      filter(variable=="pop") %>%
      select(GEOID,Tract) %>%
      arrange(GEOID) %>%
      st_transform(3488) 

# draw a buffer around the facilities
# buffer_dist is in miles so we need to multiply by 1609.34 metters/mile
communities = st_buffer(facilities,dist=buffer_dist*1609.34) 

# find the census geographies within the buffer around the facilities
buffer = st_intersection(communities,shp) %>%
         select(GEOID,Tract,facility_id)

# drop the geometry to work with the data alone
table = data
st_geometry(table) = NULL

# merge the acs and nata data
table = table %>% 
        pivot_wider(names_from=variable,values_from=estimate) %>%
        mutate(minority=(1-white/pop)*100,
               pov99=pov99/pop*100,
               pov50=pov50/pop*100,
               income=income/1000) %>%
        mutate(minority=(1-white/pop)*100) %>%
        left_join(nata_data,by=c("Tract"="Tract"))

# variables along which the comparisons should be made for the tables
comparison_vars = c("minority","income","pov99","pov50","total_risk",
                    "TRICHLOROETHYLENE")

# descriptions of the comparison variables to be included in the tables
desc_vars = c("% Minority [EJ Screen Definition]","Median Income [1,000 2019$]",
              "% Below Poverty Line","% Below Half the Poverty Line",
              "Total Cancer Risk (per million)","Trichloroethylene Cancer Risk")

# get the national level averages
summary_table = data.frame(Variable=desc_vars,National=NA)
for (v in 1:length(comparison_vars))
  summary_table[v,"National"] = sum(table$pop*table[,comparison_vars[v]],na.rm=T)/
                                sum(table$pop,na.rm=T)
  
# get the population weighted averages around the production facilities
local = table$GEOID %in% unique(buffer$GEOID)
for (v in 1:length(comparison_vars)) 
  summary_table[v,"Production Communities"] = sum(table$pop[local]*table[local,comparison_vars[v]],na.rm=T)/
                                              sum(table$pop[local],na.rm=T)
  
# only include two significant figures in the summary table
summary_table[,2:3] = signif(summary_table[,2:3],2)

```


## Characteristics of Communities with Hydrofluorocarbon Production Facilities

Hydrofluorocarbon (HFC) production facilities are identified as the `r nrow(facilities)` facilities reporting activities in `r year` under the Greenhouse Gas (GHG) Reporting Program (the most recent year available). The production facility community is defined as those Census block groups located within `r buffer_dist` miles of the facility location as reported in the GHG Reporting Program. Socioeconomic and demographic data is based on the American Community Survey 5-Year data release for `r year` (the most recent year available). Community cancer risk estimates due to air toxics exposure is based on the National Air Toxic Assessment (NATA) of 2018 (the most recent year available). The NATA estimates are only available at the Census Tract level.

The following table presents summary information for the production facility communities compared to the national average. For the production facility communities these values reflect a population weighted average across the Census block groups within the buffer distance of the facility.

```{r main_table,echo=FALSE}
kable(summary_table)
```

In general, across all HFC production facilities the communities, based on the `r buffer_dist` mile buffer distance, are general the same as national averages across the socio-economic characteristics, but have a substantially higher cumulative cancer risk from air toxics. However, this result is driven primarily from the `r sum(facilities$State=="LA")` facilities located in Louisiana in areas with elevated levels of air toxics emissions. The following tables separate out the community characteristics for the HFC production facilities outside Louisiana and inside the state.

```{r no_la,echo=FALSE}

# get the national level averages
summary_table = data.frame(Variable=desc_vars,National=NA)
for (v in 1:length(comparison_vars))
  summary_table[v,"National"] = sum(table$pop*table[,comparison_vars[v]],na.rm=T)/
                                sum(table$pop,na.rm=T)

# get the population weighted averages around the production facilities outside LA
local = table$GEOID %in% unique(buffer$GEOID) & table$State!="LA"
for (v in 1:length(comparison_vars)) 
  summary_table[v,"Outside Louisiana"] = sum(table$pop[local]*table[local,comparison_vars[v]],na.rm=T)/
                                         sum(table$pop[local],na.rm=T)

# get the population weighted averages around the production facilities inside LA
local = table$GEOID %in% unique(buffer$GEOID) & table$State=="LA"
for (v in 1:length(comparison_vars)) 
  summary_table[v,"Inside Louisiana"] = sum(table$pop[local]*table[local,comparison_vars[v]],na.rm=T)/
                                        sum(table$pop[local],na.rm=T)
  
# only include two significant figures in the summary table
summary_table[,2:4] = signif(summary_table[,2:4],2)

kable(summary_table)

```